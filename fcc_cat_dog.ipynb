{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "la_Oz6oLlub6"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # This command only in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaF8r6aOl48C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'cats_and_dogs\\\\test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m total_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;28;01mfor\u001b[39;00m r, d, files \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(train_dir)])\n\u001b[0;32m     15\u001b[0m total_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;28;01mfor\u001b[39;00m r, d, files \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(validation_dir)])\n\u001b[1;32m---> 16\u001b[0m total_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(test_dir))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Variables for pre-processing and training.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'cats_and_dogs\\\\test'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Get project files\n",
    "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
    "\n",
    "!unzip cats_and_dogs.zip\n",
    "\n",
    "PATH = 'cats_and_dogs'\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "test_dir = os.path.join(PATH, 'test')\n",
    "\n",
    "# Get number of files in each directory. The train and validation directories\n",
    "# each have the subdirecories \"dogs\" and \"cats\".\n",
    "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
    "total_test = len(os.listdir(test_dir))\n",
    "\n",
    "# Variables for pre-processing and training.\n",
    "batch_size = 128\n",
        "epochs = 25\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "This error occurs because the 'tensorflow' module is not installed in your environment. The code is trying to import TensorFlow, but it can't find the package.\n",
    "\n",
    "Would you like me to provide the corrected code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "This error occurs because the 'tensorflow' module is not installed in your environment. The code is trying to import TensorFlow, but it can't find the package.\n",
    "\n",
    "Would you like me to provide the corrected code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOJFeEfumns6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 3\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=validation_dir,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(\n",
    "    directory=PATH,\n",
    "    classes=['test'],\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TP0WA8j1mt7Q"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 4\n",
    "def plotImages(images_arr, probabilities = False):\n",
    "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
    "    if probabilities is False:\n",
    "      for img, ax in zip( images_arr, axes):\n",
    "          ax.imshow(img)\n",
    "          ax.axis('off')\n",
    "    else:\n",
    "      for img, probability, ax in zip( images_arr, probabilities, axes):\n",
    "          ax.imshow(img)\n",
    "          ax.axis('off')\n",
    "          if probability > 0.5:\n",
    "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
    "          else:\n",
    "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
    "    plt.show()\n",
    "\n",
    "sample_training_images, _ = next(train_data_gen)\n",
    "plotImages(sample_training_images[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-32RRLY_3voj"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 5\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=40,\n",
    "                                          width_shift_range=0.2,\n",
    "                                          height_shift_range=0.2,\n",
    "                                          shear_range=0.2,\n",
    "                                          zoom_range=0.2,\n",
    "                                          horizontal_flip=True,\n",
    "                                          fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkwq2LFvqabS"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 6\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8aZkwMam4UY"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
      "source": [
        "# 7\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1niQDz5x6K7y"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 8\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xS51mB56OAC"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 9\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYrSifOit2aK"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 10\n",
    "# Predict\n",
    "test_data_gen.reset()\n",
    "steps = int(np.ceil(total_test / batch_size))\n",
    "probabilities = model.predict(test_data_gen, steps=steps).flatten()\n",
    "\n",
    "# Fetch test images (one batch is enough since there are only 50)\n",
    "test_data_gen.reset()\n",
    "test_images = next(test_data_gen)\n",
    "\n",
    "plotImages(test_images[:len(probabilities)], probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9w_HE1Lc3XD"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IH86Ux_u7TZ"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 11\n",
    "answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
    "            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
    "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
    "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
    "            0, 0, 0, 0, 0, 0]\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for probability, answer in zip(probabilities, answers):\n",
    "  if round(probability) == answer:\n",
    "    correct +=1\n",
    "\n",
    "percentage_identified = (correct / len(answers)) * 100\n",
    "\n",
    "passed_challenge = percentage_identified >= 63\n",
    "\n",
    "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
    "\n",
    "if passed_challenge:\n",
    "  print(\"You passed the challenge!\")\n",
    "else:\n",
    "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "fcc_cat_dog.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
